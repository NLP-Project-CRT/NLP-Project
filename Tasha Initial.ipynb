{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/natasharivers/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/natasharivers/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#custome modules\n",
    "import acquire as a\n",
    "import wrangle as w\n",
    "\n",
    "#visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# import standard libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# import file managers\n",
    "from os.path import isfile\n",
    "import pickle\n",
    "\n",
    "# import json handler\n",
    "import json\n",
    "\n",
    "# import language detector\n",
    "from langdetect import detect\n",
    "\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#modeling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire/Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= w.wrangle_github_repos(new_pickles=False, get_new_links=False,\n",
    "                                             number_of_pages=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    '''\n",
    "    This function is a simplified text cleaning function\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return re.sub(r\"[^a-z0-9\\s]\", '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the count for each language\n",
    "df.programming_language.value_counts()\n",
    "\n",
    "#python appears to be the most used language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at all python \n",
    "df[df.programming_language == 'Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python clean only\n",
    "python_words = (' '.join(df[df.programming_language == 'Python'].cleaned_readme))\n",
    "python_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean java only\n",
    "java_words = (' '.join(df[df.programming_language == 'JavaScript'].cleaned_readme))\n",
    "\n",
    "#clean Jupyter Notebook only\n",
    "jupyter_words = (' '.join(df[df.programming_language == 'Jupyter Notebook'].cleaned_readme))\n",
    "\n",
    "#html clean only\n",
    "html_words = (' '.join(df[df.programming_language == 'HTML'].cleaned_readme))\n",
    "\n",
    "#typescript clean only\n",
    "type_words = (' '.join(df[df.programming_language == 'TypeScript'].cleaned_readme))\n",
    "\n",
    "#r clean only\n",
    "r_words = (' '.join(df[df.programming_language == 'R'].cleaned_readme))\n",
    "\n",
    "#all clean text\n",
    "all_words = (' '.join(df.cleaned_readme))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn all words into a series\n",
    "#get value count of all words\n",
    "pd.Series(all_words.split()).value_counts()\n",
    "\n",
    "#removing stopwords would change this count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a series with words split and value counts for each word\n",
    "python_freq = pd.Series(python_words.split()).value_counts()\n",
    "java_freq = pd.Series(java_words.split()).value_counts()\n",
    "jupyter_freq = pd.Series(jupyter_words.split()).value_counts()\n",
    "html_freq = pd.Series(html_words.split()).value_counts()\n",
    "type_freq = pd.Series(type_words.split()).value_counts()\n",
    "r_freq = pd.Series(r_words.split()).value_counts()\n",
    "all_freq = pd.Series(all_words.split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all frequency into single Series\n",
    "word_counts = pd.concat([python_freq, java_freq, jupyter_freq, html_freq, type_freq, r_freq, all_freq], axis=1).fillna(0).astype(int)\n",
    "\n",
    "#word count for each language type\n",
    "word_counts.columns = ['python', 'java', 'jupyter', 'html', 'typescript', 'r', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted by most common to most common in 'all' \n",
    "word_counts.sort_values('all', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictate size of figure\n",
    "plt.rc('figure', figsize=(14, 8))\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using 'all' languages\n",
    "#visualize top 10\n",
    "word_counts.sort_values('all', ascending=False).head(10)[['python', 'java', 'jupyter', 'html', 'typescript', 'r']].plot.barh()\n",
    "\n",
    "plt.title('Top 10 words by Language')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual proportions\n",
    "#axis=1 in .apply means row by row\n",
    "word_counts.sort_values(by='all', ascending=False).head(10).apply(lambda row: row/ row['all'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize all languages as percent of 'all'\n",
    "(word_counts.sort_values(by='all', ascending=False)\n",
    " .head(10)\n",
    " .apply(lambda row: row/ row['all'],axis=1)\n",
    " .drop(columns='all')\n",
    " .plot.barh(stacked=True))\n",
    "plt.title('% of 10  most common words by language')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see most common bigrams in python languages\n",
    "pd.Series(nltk.bigrams(python_words.split())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see most common bigrams in JavaScript language\n",
    "pd.Series(nltk.bigrams(java_words.split())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see most common bigrams in JupyterNotebook language\n",
    "pd.Series(nltk.bigrams(jupyter_words.split())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see most common bigrams in HTML language\n",
    "pd.Series(nltk.bigrams(html_words.split())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TypeScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see most common bigrams in TypeScript language\n",
    "pd.Series(nltk.bigrams(type_words.split())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see most common bigrams in R language\n",
    "pd.Series(nltk.bigrams(r_words.split())).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize top ten for all languages\n",
    "pd.Series(nltk.bigrams(all_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 most common all languages bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('Frequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WordCloud(background_color='white', width=800, height=600).generate(python_words)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WordCloud(background_color='white', width=800, height=600).generate(java_words)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WordCloud(background_color='white', width=800, height=600).generate(jupyter_words)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WordCloud(background_color='white', width=800, height=600).generate(html_words)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TypeScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WordCloud(background_color='white', width=800, height=600).generate(type_words)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WordCloud(background_color='white', width=800, height=600).generate(r_words)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term frequency\n",
    "cv = CountVectorizer()\n",
    "#identify X\n",
    "X = cv.fit_transform(df.cleaned_readme)\n",
    "#identify target (language)\n",
    "y = df.programming_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find value counts to find baseline language\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = (y_train == 'Python').mean()\n",
    "print(f'Baseline accuracy is: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model - decision tree classifier\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "\n",
    "#fit\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#get scores \n",
    "print(f'training score for Decision Tree(max_depth =5): {tree.score(X_train, y_train):.2%}')\n",
    "print(f'test score for Decision Tree(max_depth =5): {tree.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model - decision tree classifier\n",
    "tree2 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "#fit the model\n",
    "tree2.fit(X_train, y_train)\n",
    "\n",
    "#get scores \n",
    "print(f'training score for Decision Tree(max_depth =3): {tree2.score(X_train, y_train):.2%}')\n",
    "print(f'test score for Decision Tree(max_depth =3): {tree2.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model - decision tree classifier\n",
    "tree3 = DecisionTreeClassifier(max_depth=10, random_state=123)\n",
    "\n",
    "#fit the model\n",
    "tree3.fit(X_train, y_train)\n",
    "\n",
    "#get scores \n",
    "print(f'training score for Decision Tree(max_depth =10): {tree3.score(X_train, y_train):.2%}')\n",
    "print(f'test score for Decision Tree(max_depth =10): {tree3.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.cleaned_readme)\n",
    "y = df.programming_language\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try on Lemmatized readme instead of cleaned readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term frequency\n",
    "cv_lem = CountVectorizer()\n",
    "#identify X\n",
    "X_lem = cv_lem.fit_transform(df.lemmatized_readme)\n",
    "#identify target (language)\n",
    "y_lem = df.programming_language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
